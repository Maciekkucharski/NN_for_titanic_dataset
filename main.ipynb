{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89a239a",
   "metadata": {},
   "source": [
    "### DATA GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f80f3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from torch import tensor\n",
    "\n",
    "path = Path('titanic')\n",
    "if not path.exists():\n",
    "    import zipfile,kaggle\n",
    "    kaggle.api.competition_download_cli(str(path))\n",
    "    zipfile.ZipFile(f'{path}.zip').extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2df86f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                    Name     Sex   Age  SibSp  \\\n",
       "0                                Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "2                                 Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3           Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                               Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                   ...     ...   ...    ...   \n",
       "886                                Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                         Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888             Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                                Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                  Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f545767b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a145f2e4",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with most common values\n",
    "df.fillna(df.mode().iloc[0], inplace=True)\n",
    "# Convert categorical variables to numerical\n",
    "df = pd.get_dummies(df, columns=[\"Pclass\", \"Sex\", \"Embarked\"])\n",
    "\n",
    "# Normalize fare column\n",
    "df['LogFare'] = np.log(df['Fare']+1)\n",
    "\n",
    "# select dependent and independent variables\n",
    "indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare', 'Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "dep_cols = ['Survived']\n",
    "\n",
    "# Convert to numpy arrays\n",
    "df[indep_cols] = df[indep_cols].astype(float)\n",
    "\n",
    "#Prepare predictors and targets\n",
    "predictors = tensor(df[indep_cols].values, dtype=torch.float)\n",
    "targets = tensor(df[dep_cols].values, dtype=torch.float)  # Ensure targets are float\n",
    "\n",
    "#Normalize predictors\n",
    "vals, indices = predictors.max(dim=0)\n",
    "predictors = predictors/vals\n",
    "\n",
    "from fastai.data.transforms import RandomSplitter\n",
    "from fastai.data.all import range_of\n",
    "\n",
    "# Use RandomSplitter to get train/val indices\n",
    "splitter = RandomSplitter(valid_pct=0.2, seed=42)\n",
    "train_idx, val_idx = splitter(range_of(predictors))\n",
    "\n",
    "train_predictors = predictors[train_idx]\n",
    "train_targets = targets[train_idx]\n",
    "val_predictors = predictors[val_idx]\n",
    "val_targets = targets[val_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899f6d4",
   "metadata": {},
   "source": [
    "### Create Neural Network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d20c3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def initialize_coeffs(layer_sizes):\n",
    "    layers: List[torch.Tensor] = []\n",
    "    constants: List[torch.Tensor] = []\n",
    "    for i in range(len(layer_sizes)-1):\n",
    "        layers.append((torch.rand(layer_sizes[i], layer_sizes[i+1])-0.3) / layer_sizes[i+1] * 4)\n",
    "        constants.append(torch.rand(1)[0]*0.1)\n",
    "    for l in layers+constants: l.requires_grad_()\n",
    "    return layers, constants\n",
    "\n",
    "def calc_preds(coeffs: Tuple[List[torch.Tensor]], predictors: List[torch.Tensor]):\n",
    "        layers, constants = coeffs\n",
    "        n = len(layers)\n",
    "        res = predictors\n",
    "        for i in range(n):\n",
    "            res = res@layers[i] + constants[i]\n",
    "            if i != n-1: res = torch.relu(res)\n",
    "        return torch.sigmoid(res)\n",
    "\n",
    "def calc_loss(coeffs: Tuple[List[torch.Tensor]], predictors: List[torch.Tensor], targets: List[torch.Tensor]): return torch.abs(calc_preds(coeffs, predictors) -targets).mean()\n",
    "\n",
    "def update_coeffs(coeffs: Tuple[List[torch.Tensor]], lr: int):\n",
    "    layers, constants = coeffs\n",
    "    with torch.no_grad(): \n",
    "        for layer in layers + constants:\n",
    "            layer.sub_(layer.grad * lr)\n",
    "            layer.grad.zero_()\n",
    "\n",
    "def one_epoch(coeffs: Tuple[List[torch.Tensor]], predictors: List[torch.Tensor], targets: List[torch.Tensor], lr: int):\n",
    "    loss = calc_loss(coeffs, predictors, targets)\n",
    "    loss.backward()\n",
    "    update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")\n",
    "\n",
    "def train_model(predictors, targets, layer_sizes, epochs=10, lr=0.1):\n",
    "    coeffs = initialize_coeffs(layer_sizes)\n",
    "    for i in range(epochs):\n",
    "        one_epoch(coeffs, predictors, targets, lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f8aa680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_accuracy(coeffs: Tuple[List[torch.Tensor]], predictors: List[torch.Tensor], targets: List[torch.Tensor]) -> float:\n",
    "    return (targets.bool()==(calc_preds(coeffs, predictors)>0.5)).float().mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a2c22",
   "metadata": {},
   "source": [
    "### Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "08f4658f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609; 0.568; 0.453; 0.397; 0.357; 0.333; 0.310; 0.291; 0.277; 0.267; 0.259; 0.252; 0.247; 0.243; 0.240; 0.237; 0.235; 0.232; 0.231; 0.229; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8034)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hidden layer with 10 neurons\n",
    "coeffs = train_model(train_predictors, train_targets, [len(indep_cols), 10,  1], epochs=20, lr=0.5)\n",
    "calc_accuracy(coeffs, val_predictors, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d7697246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603; 0.585; 0.511; 0.497; 0.491; 0.478; 0.469; 0.483; 0.462; 0.439; 0.435; 0.439; 0.474; 0.463; 0.436; 0.396; 0.388; 0.380; 0.374; 0.368; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7640)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with specified layer sizes\n",
    "coeffs = train_model(predictors, targets, [len(indep_cols), 10, 10, 1], epochs=20, lr=0.5)\n",
    "calc_accuracy(coeffs, val_predictors, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e0e15793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594; 0.555; 0.503; 0.500; 0.494; 0.489; 0.486; 0.516; 0.494; 0.490; 0.488; 0.487; 0.485; 0.483; 0.482; 0.480; 0.478; 0.477; 0.475; 0.474; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5955)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Three hidden layers with 10, neurons each\n",
    "coeffs = train_model(predictors, targets, [len(indep_cols), 10, 10, 10, 1], epochs=20, lr=0.5)\n",
    "calc_accuracy(coeffs, val_predictors, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0e7038a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.615; 0.615; 0.615; 0.613; 0.606; 0.504; 0.502; 0.500; 0.498; 0.497; 0.495; 0.493; 0.492; 0.490; 0.488; 0.487; 0.485; 0.483; 0.482; 0.480; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5955)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Five hidden layers with 10, neurons each\n",
    "coeffs = train_model(predictors, targets, [len(indep_cols), 10, 10, 10, 10, 10, 1], epochs=20, lr=0.5)\n",
    "calc_accuracy(coeffs, val_predictors, val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca9198",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As we can see the loss and accuracy is coming down with each layer, this might be caused, by not big enough dataset, and also, in that case the data cant have enough features to support the amount of neurons, the problem just doesnt need such a big amount of neurons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
